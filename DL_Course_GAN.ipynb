{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code an AutoEncoder using Keras\n",
    "<br> # https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "import random\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# AlexNet Dependencies\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.layers import Input, Dropout, Dense, Activation,BatchNormalization, Flatten, Conv2D, LeakyReLU, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Model, model_from_json\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts integer labels into one-hot vectors\n",
    "def to_one_hot(labels, n_classes, p_max = 1.0):\n",
    "    # Calculate the minimum probability of class based on max probability\n",
    "    p_min = 0.0 if p_max == 1.0 else (1.0 - p_max)/(n_classes - 1)\n",
    "\n",
    "    # allocate memory for one hot labels\n",
    "    labels = labels.astype(np.int32)\n",
    "    n_labels = labels.shape[0]\n",
    "    oh_labels = np.full((n_labels, n_classes), p_min)\n",
    "    # minus 1 because Matlab uses 1 based indexing\n",
    "    oh_labels[np.arange(n_labels), labels-1] = p_max\n",
    "    return oh_labels\n",
    "\n",
    "def to_int_label(labels):\n",
    "    int_labels = np.zeros((len(labels),))\n",
    "    for i in range(len(labels)):\n",
    "        int_labels[i] = np.argmax(labels[i])\n",
    "    return int_labels\n",
    "\n",
    "# Convert batch, pixels --> batch, rows, cols, 1_channel\n",
    "def to_img(x):\n",
    "    return np.reshape(x, [-1, im_rows, im_cols, 1])\n",
    "\n",
    "\n",
    "# Restore values from memory (TF also supports restoring from a file)\n",
    "def set_best_vars(sess, best_vars_vals, trainable_vars):\n",
    "    restore_ops = [avar.assign(best_val) for best_val, avar in zip(best_vars_vals, trainable_vars)]\n",
    "    sess.run(restore_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To speed up validation\n",
    "MAX_VALIDATION_SAMPLES = int(2000) # at most 10,000 in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_FILE = '../training.mat'\n",
    "VALIDATION_FILE = '../validation.mat'\n",
    "TESTING_FILE = '../testing.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data\n",
      "Loading Validation Data\n",
      "Loading Testing Data\n"
     ]
    }
   ],
   "source": [
    "## Data\n",
    "print('Loading Training Data')\n",
    "training_data = sio.loadmat(TRAINING_FILE, squeeze_me=True)\n",
    "training_ims = training_data['data'].T  # .T --> transpose\n",
    "training_labels = training_data['labels']\n",
    "\n",
    "# Validation Data\n",
    "print('Loading Validation Data')\n",
    "validation_data = sio.loadmat(VALIDATION_FILE, squeeze_me=True)\n",
    "validation_ims = validation_data['data'].T\n",
    "validation_labels = validation_data['labels']\n",
    "# Limit our Validation data since we don't really need 10k of them\n",
    "validation_ims = validation_ims[:MAX_VALIDATION_SAMPLES]\n",
    "validation_labels = validation_labels[:MAX_VALIDATION_SAMPLES]\n",
    "\n",
    "\n",
    "# Testing data\n",
    "print('Loading Testing Data')\n",
    "testing_data = sio.loadmat(TESTING_FILE, squeeze_me=True)\n",
    "testing_ims = testing_data['data'].T\n",
    "testing_labels = testing_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows/Cols: 28\n",
      "Number of Classes: 10\n"
     ]
    }
   ],
   "source": [
    "## Data attributes (look them up, but are effectively constant)\n",
    "# These could be hard coded, but extracting them from the data anyway\n",
    "im_rows = im_cols = int(np.sqrt(testing_ims.shape[1]))\n",
    "print('Number of Rows/Cols:', im_rows)\n",
    "num_classes = int(np.amax(testing_labels))\n",
    "print('Number of Classes:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformating labels to one-hot\n"
     ]
    }
   ],
   "source": [
    "## Data preprocessing\n",
    "print('Reformating labels to one-hot')\n",
    "training_labels   = to_one_hot(training_labels, num_classes)\n",
    "validation_labels = to_one_hot(validation_labels, num_classes)\n",
    "testing_labels    = to_one_hot(testing_labels, num_classes)\n",
    "\n",
    "# print('Reshaping data from [img, pixels] to [img, row, col, channel]')\n",
    "# training_ims   = np.reshape(training_ims, (-1, im_rows, im_cols, 1))\n",
    "# validation_ims = np.reshape(validation_ims, (-1, im_rows, im_cols, 1))\n",
    "# testing_ims    = np.reshape(testing_ims, (-1, im_rows, im_cols, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(training_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "(2000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = training_ims.astype('float32') / 255.\n",
    "x_val   = validation_ims.astype('float32') / 255.\n",
    "x_test  = testing_ims.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train.reshape((len(x_train),28,28,1))\n",
    "x_val   = x_val.reshape((len(x_val),28,28,1))\n",
    "x_test  = x_test.reshape((len(x_test),28,28,1))\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_fake_samples(n_samples):\n",
    "    # generate uniform random numbers in [0,1]\n",
    "    X = rand(28 * 28 * n_samples)\n",
    "    # reshape into a batch of grayscale images\n",
    "    X = X.reshape((n_samples, 28, 28, 1))\n",
    "    # generate 'fake' class labels (0)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_batch = int(n_batch / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = [im_rows,im_cols,1]\n",
    "BATCH_SIZE = int(100)\n",
    "MAX_ITER = int(500000)  # 5 million should be enough\n",
    "WEIGHT_DECAY = 5e-4  # This is what AlexNet used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Discriminator(input_shape=(28,28,1)):\n",
    "    \n",
    "    # Input Image\n",
    "    X_input = Input(shape=input_shape,name = \"input\")\n",
    "    \n",
    "    X = Conv2D(64, (3,3), strides=(2, 2), padding='same', name=\"conv0\")(X_input)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "    \n",
    "    X = Conv2D(64, (3,3), strides=(2, 2), padding='same', name=\"conv1\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    X = Dense(1, activation = 'sigmoid', name = \"fc0\")(X)\n",
    "    \n",
    "    # Model that maps input to its reconstruction\n",
    "    model = Model(inputs = X_input, outputs = X, name='discriminator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "fc0 (Dense)                  (None, 1)                 3137      \n",
      "=================================================================\n",
      "Total params: 40,705\n",
      "Trainable params: 40,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer = Adam(lr=0.0002, beta_1=0.5) , loss = 'binary_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected fc0 to have shape (1,) but got array with shape (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-2991d6dc30c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m history = m.fit(x_train,training_labels, \n\u001b[0;32m      2\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                 validation_data=(x_val, validation_labels))\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\1130135\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'steps_per_epoch'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1536\u001b[1;33m         validation_split=validation_split)\n\u001b[0m\u001b[0;32m   1537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1130135\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[1;32m--> 992\u001b[1;33m                                                      class_weight, batch_size)\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1130135\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   1152\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m           exception_prefix='target')\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m       \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1130135\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    333\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected fc0 to have shape (1,) but got array with shape (10,)"
     ]
    }
   ],
   "source": [
    "history = m.fit(x_train,training_labels, \n",
    "                batch_size=BATCH_SIZE, epochs=50, \n",
    "                validation_data=(x_val, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import randint, rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances    \n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    \n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_fake_samples(n_samples):\n",
    "    # generate uniform random numbers in [0,1]\n",
    "    X = rand(28 * 28 * n_samples)\n",
    "    # reshape into a batch of grayscale images\n",
    "    X = X.reshape((n_samples, 28, 28, 1))\n",
    "    # generate 'fake' class labels (0)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_discriminator(model, dataset, n_iter=100, n_batch=256):\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_iter):\n",
    "        # get randomly selected 'real' samples\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        # update discriminator on real samples\n",
    "        _, real_acc = model.train_on_batch(X_real, y_real)\n",
    "        # generate 'fake' examples\n",
    "        X_fake, y_fake = generate_fake_samples(half_batch)\n",
    "        # update discriminator on fake samples\n",
    "        _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
    "        # summarize performance\n",
    "        print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "128\n",
      ">1 real=50% fake=36%\n",
      "50000\n",
      "128\n",
      ">2 real=100% fake=84%\n",
      "50000\n",
      "128\n",
      ">3 real=100% fake=98%\n",
      "50000\n",
      "128\n",
      ">4 real=100% fake=99%\n",
      "50000\n",
      "128\n",
      ">5 real=99% fake=100%\n",
      "50000\n",
      "128\n",
      ">6 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">7 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">8 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">9 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">10 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">11 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">12 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">13 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">14 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">15 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">16 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">17 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">18 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">19 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">20 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">21 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">22 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">23 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">24 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">25 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">26 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">27 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">28 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">29 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">30 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">31 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">32 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">33 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">34 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">35 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">36 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">37 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">38 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">39 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">40 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">41 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">42 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">43 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">44 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">45 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">46 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">47 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">48 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">49 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">50 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">51 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">52 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">53 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">54 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">55 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">56 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">57 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">58 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">59 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">60 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">61 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">62 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">63 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">64 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">65 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">66 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">67 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">68 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">69 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">70 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">71 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">72 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">73 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">74 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">75 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">76 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">77 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">78 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">79 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">80 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">81 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">82 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">83 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">84 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">85 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">86 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">87 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">88 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">89 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">90 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">91 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">92 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">93 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">94 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">95 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">96 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">97 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">98 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">99 real=100% fake=100%\n",
      "50000\n",
      "128\n",
      ">100 real=100% fake=100%\n"
     ]
    }
   ],
   "source": [
    "# define the discriminator model\n",
    "model = Discriminator()\n",
    "\n",
    "model.compile(optimizer = Adam(lr=0.0002, beta_1=0.5) , loss = 'binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "# load image data\n",
    "dataset = x_train\n",
    "# fit the model\n",
    "train_discriminator(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Dimension\n",
    "input_dim = im_rows*im_cols\n",
    "\n",
    "# Dimension of encoded representation\n",
    "encoding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AutoEncoder(input_dim, encoding_dim):\n",
    "    \n",
    "    # Input Image\n",
    "    X_input = Input(shape=(input_dim,),name = \"input\")\n",
    "    \n",
    "    # Encoded representation of input\n",
    "    X = Dense(encoding_dim, activation='relu', name = \"encoder\")(X_input)\n",
    "    \n",
    "    # Decoded / lossy reconstruction of input\n",
    "    X = Dense(input_dim, activation='sigmoid', name = \"decoder\")(X)\n",
    "    \n",
    "    # Model that maps input to its reconstruction\n",
    "    model = Model(inputs = X_input, outputs = X, name='AutoEncoder')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder(input_dim, encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "decoder (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer = 'adam' , loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.4959 - val_loss: 0.2149\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0994 - val_loss: 0.0427\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0274 - val_loss: 0.0179\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 22us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.0038 - val_loss: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eb2a548ba8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_name = 'encoder'\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(layer_name).output)\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "\n",
    "layer_name = 'decoder'\n",
    "decoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(layer_name).output)\n",
    "decoded_imgs = decoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIBC8KAGAAAAAACgEP8fMa6i58lEWlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb2b4f16d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of images to plot\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    index = random.randint(0,len(x_test))\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[index].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[index].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eb2b4d1ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AutoEncoder(input_shape=(28,28,1)):\n",
    "    \n",
    "    # Input Image\n",
    "    X_input = Input(shape=input_shape,name = \"input\")\n",
    "    \n",
    "    X = Conv2D(32, (3,3), activation='relu', padding='same', name=\"conv0\")(X_input)\n",
    "    X = MaxPooling2D((2,2), padding='same', name = 'max0')(X)\n",
    "    X = Conv2D(32, (3,3), activation='relu', padding='same', name=\"conv1\")(X)\n",
    "    encoded = MaxPooling2D((2,2), padding='same', name = 'encoded')(X)\n",
    "    \n",
    "    X = Conv2D(32, (3,3), activation='relu', padding='same', name=\"conv2\")(encoded)\n",
    "    X = UpSampling2D((2,2), name = 'upsample0')(X)\n",
    "    X = Conv2D(32, (3,3), activation='relu', padding='same', name=\"conv3\")(X)\n",
    "    X = UpSampling2D((2,2), name = 'upsample1')(X)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name=\"decoded\")(X)\n",
    "    \n",
    "    # Model that maps input to its reconstruction\n",
    "    model = Model(inputs = X_input, outputs = decoded, name='AutoEncoder')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max0 (MaxPooling2D)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "encoded (MaxPooling2D)       (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "upsample0 (UpSampling2D)     (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "upsample1 (UpSampling2D)     (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoded (Conv2D)             (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 28,353\n",
      "Trainable params: 28,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer = 'adam' , loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 2.3840e-04 - val_loss: 1.6345e-04\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 1.2468e-04 - val_loss: 9.4975e-05\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 7.8641e-05 - val_loss: 6.5582e-05\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 5.7653e-05 - val_loss: 5.1147e-05\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 114s 2ms/step - loss: 4.6810e-05 - val_loss: 4.3261e-05\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 4.0657e-05 - val_loss: 3.8600e-05\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 3.6919e-05 - val_loss: 3.5684e-05\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 3.4528e-05 - val_loss: 3.3782e-05\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 3.2943e-05 - val_loss: 3.2498e-05\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 3.1862e-05 - val_loss: 3.1611e-05\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 3.1105e-05 - val_loss: 3.0985e-05\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 3.0568e-05 - val_loss: 3.0536e-05\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 3.0179e-05 - val_loss: 3.0210e-05\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 2.9896e-05 - val_loss: 2.9970e-05\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 2.9687e-05 - val_loss: 2.9792e-05\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 2.9530e-05 - val_loss: 2.9659e-05\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 98s 2ms/step - loss: 2.9413e-05 - val_loss: 2.9560e-05\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 2.9325e-05 - val_loss: 2.9485e-05\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 2.9259e-05 - val_loss: 2.9428e-05\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 2.9209e-05 - val_loss: 2.9386e-05\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 2.9170e-05 - val_loss: 2.9353e-05\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 2.9142e-05 - val_loss: 2.9329e-05\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 2.9121e-05 - val_loss: 2.9310e-05\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 2.9104e-05 - val_loss: 2.9296e-05\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 96s 2ms/step - loss: 2.9092e-05 - val_loss: 2.9285e-05\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 2.9083e-05 - val_loss: 2.9277e-05\n",
      "Epoch 27/100\n",
      "16128/50000 [========>.....................] - ETA: 1:00 - loss: 2.9057e-05"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "history = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_name = 'decoded'\n",
    "decoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(layer_name).output)\n",
    "decoded_imgs = decoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of images to plot\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    index = random.randint(0,len(x_test))\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[index].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[index].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
